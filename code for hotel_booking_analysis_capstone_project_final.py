# -*- coding: utf-8 -*-
"""Hotel Booking Analysis - Capstone Project final.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1f86Aa30RYKFYLViR0qwyRXhOaAq7ToFh

#EDA Hotel Booking Analysis
##Have you ever wondered when the best time of year to book a hotel room is? Or the optimal length of stay in order to get the best daily rate? What if you wanted to predict whether or not a hotel was likely to receive a disproportionately high number of special requests? This hotel booking dataset can help you explore those questions!

## <b>This data set contains booking information for a city hotel and a resort hotel, and includes information such as when the booking was made, length of stay, the number of adults, children, and/or babies, and the number of available parking spaces, among other things. All personally identifying information has been removed from the data. </b>

## <b> Explore and analyze the data to discover important factors that govern the bookings. </b>
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from mpl_toolkits import mplot3d
from datetime import datetime
!pip install colorama
from colorama import Fore
import warnings
warnings.filterwarnings("ignore")

df=pd.read_csv('/content/drive/MyDrive/Copy of Hotel Bookings.csv')

df.head()

df.tail()

df.info()

df.isna().sum()

df.describe()                                                                   #minimum adr is -ve which is not possible lets look into it

print(df[df.adr<=0].shape) # there are a lot of anomalies in data based on adr because it is not possible that a person is charged 0 dollars for his/her stay until he has some membership which is not displayed in data thus i will remove them
df=df[df.adr>0]

column_list=['country','hotel', 'is_canceled', 'lead_time', 'arrival_date_year',                              #Forming a counting list with top 10 contributors 
       'arrival_date_month', 'arrival_date_week_number',
       'arrival_date_day_of_month', 'stays_in_weekend_nights',
       'stays_in_week_nights', 'adults', 'children', 'babies', 'meal',
        'market_segment', 'distribution_channel',
       'is_repeated_guest', 'previous_cancellations',
       'previous_bookings_not_canceled', 'reserved_room_type',
       'assigned_room_type', 'booking_changes', 'deposit_type', 'agent',
       'company', 'days_in_waiting_list', 'customer_type', 'adr',
       'required_car_parking_spaces', 'total_of_special_requests',
       'reservation_status', 'reservation_status_date']
count_dataset=pd.DataFrame()
distinct_features=[]                                                                                          #Empty list to know the number of distict features,sum of all these values, and sum of values top 10 comprises
for i in column_list:                                                                                               
  count_dataset[i]= pd.Series(df[i].value_counts().sort_values(ascending=False).head(10).index)      
  count_dataset[f'{i}_count']=pd.Series(df[i].value_counts().sort_values(ascending=False).head(10).values).astype('int')   
  distinct_features.append((len(df[i].value_counts().index),df[i].value_counts().sum(),df[i].value_counts().sort_values(ascending=False).head(10).sum())) 
final_tally=list(zip(column_list,distinct_features))                                                           #Zipping with column_list
count_dataset   
col_ref={}  
for i in column_list:
  if i in ['children','country','agent','company']:                                                           #colur red shows the features having some Nan
    col_ref[i]='background-color: red'  
  else:
    col_ref[i]='background-color: blue'                                                                       #colur blue shows the features 
  temp=f'{i}_count'
  col_ref[temp]='background-color: green'                                                                     #colur blue shows the count
def Nan_as_black(val):
  if str(val)=='nan':
    color = 'black'
    return 'color: %s' % color
count_dataset=count_dataset.style.apply(lambda x: pd.DataFrame(col_ref, index=count_dataset.index, columns=count_dataset.columns).fillna(''), axis=None).highlight_null('black').applymap(Nan_as_black)
count_dataset

final_tally

df.children[df['children'].isna()]=0                                            # will replace 4 Nan values for children by 0 as it wont affect our data in any way    
try:
  df.drop('company',axis=1,inplace=True)                                        # company data is so less that it is almost non reproducible, if reproduced could lead to wrong interpretations,and their are no basis on which clusters could be formed thus i will drop the entire columns
except:
  pass
top5_country=df['country'].value_counts().sort_values(ascending=False).head(5)  # for countries i will distribute the values  between top 5 as they hold exclusive dominance usnig random forest
top30_agents=df['agent'].value_counts().sort_values(ascending=False).head(5)    # for agents i will distribute the values between top 5 as they hold exclusive dominance usnig random forest
print(top5_country.sum())
print(top30_agents.sum())

df_top5_country=df[(df['country']=='GBR') | (df['country']=='PRT')| (df['country']=='FRA')| (df['country']=='ESP')| (df['country']=='DEU')] 
nan_country=df[df['country'].isna()]
'''-------------------------------------------------------------------------------------------------------------------------predicting countries----------------------------'''
def country2int(x):
  country_list=['PRT','GBR','FRA','ESP','DEU']
  count=0
  for i in country_list:
    count+=1
    if x==i:
      return count
    
df_top5_country['country']=df_top5_country['country'].apply(lambda x :country2int(x))
X_train=df_top5_country[df_top5_country.describe().columns].drop(['country','agent'],axis=1)
y_train=df_top5_country['country']
X_test= nan_country[nan_country.describe().columns].drop(['agent'],axis=1)
def RandomForest_model(X_train,y_train,X_test):
  model=RandomForestClassifier(n_estimators=100,max_depth=20,random_state=0)
  model.fit(X_train,y_train)
  y_pred=model.predict(X_test)
  return y_pred
y_pred=RandomForest_model(X_train,y_train,X_test)
nan_country['country']=y_pred
def int2country(x):
  country_list=['PRT','GBR','FRA','ESP','DEU']
  for i in range(1,6):
    if str(x)==str(i):
      return country_list[i-1]
nan_country['country']=nan_country['country'].apply(lambda x : int2country(x))
nan_country.country.value_counts()
for i in nan_country.index:
    df.loc[i]=nan_country.loc[i]

df_top5_agent=df[(df['agent']==9) | (df['agent']==240)| (df['agent']==1)| (df['agent']==14)| (df['agent']==7)] 
nan_agent=df[df['agent'].isna()]
'''-------------------------------------------------------------------------------------------------------------------------predicting agents----------------------------'''
X_train=df_top5_agent[df_top5_agent.describe().columns].drop(['agent'],axis=1)
y_train=df_top5_agent['agent']
X_test= nan_agent[nan_agent.describe().columns].drop(['agent'],axis=1)
y_pred=RandomForest_model(X_train,y_train,X_test)
nan_agent['agent']=y_pred
print(nan_agent.agent.value_counts())
index_list=[]
for i in nan_agent.index:
  index_list.append(i)
df.loc[index_list]=nan_agent.loc[index_list]

df.isna().sum()                                                                 #no null values are their

corr = df.corr()                                                                #plotting co-relation chart
plt.figure(figsize=(25,15))
sns.heatmap(corr, annot=True)
plt.show()                                                                      #there is not much co-relation between any of the feature

"""#Comparision between city and resort hotel"""

columns = ['is_canceled',
       'arrival_date_day_of_month', 'stays_in_weekend_nights',
       'stays_in_week_nights','meal',
       'country', 'market_segment', 'distribution_channel',
       'is_repeated_guest', 
       'reserved_room_type',
       'assigned_room_type', 'deposit_type', 'agent',
       'customer_type', 'adr',
       'total_of_special_requests',
       'reservation_status', ]     
df_city_hotel=df[df.hotel=='City Hotel']                                        # head on comparision between city and resort hotel
df_Resort_hotel= df[df.hotel=='Resort Hotel']
fig, axs = plt.subplots(len(columns),figsize=(30,200))
count=0
for i in columns:
    sns.countplot(df[i],ax=axs[count],order=df[i].value_counts().iloc[:53].index,hue=df.hotel)

    plt.tick_params(labelrotation=45)
    count+=1

dist=['lead_time','days_in_waiting_list','agent','adr','stays_in_weekend_nights','stays_in_week_nights','booking_changes','previous_bookings_not_canceled','previous_cancellations','adults','children','babies','required_car_parking_spaces']
fig, axs = plt.subplots(len(dist),1,figsize=(30,100))
count=0
for i in dist:
    sns.distplot(df_city_hotel[i],ax=axs[count],color='red')
    sns.distplot(df_Resort_hotel[i],ax=axs[count],color='blue')
    count+=1

columns2=['arrival_date_year','arrival_date_month', 'arrival_date_week_number']
fig, axs = plt.subplots(len(columns2),figsize=(30,40))
count=0
for i in columns2:
    sns.countplot(df[i],ax=axs[count], hue=df.hotel)
    plt.tick_params(labelrotation=45)
    count+=1

"""#Timing Analysis"""

df=df[df.adr <600]                                                                 #there is only one value above 500 adr thus removing it as it is anomaly

#converting date column into datetime format
try:
  df['temp_date_month']=df['arrival_date_month'].apply(lambda x : datetime.strptime(x,'%B'))
except :
  pass
df['Month']=df['temp_date_month'].apply(lambda x: int(str(x)[5:7]))
df.head()

fig = plt.figure(figsize = (20, 10))
ax = plt.axes(projection ="3d")
# Creating color map
my_cmap = plt.get_cmap('hsv')
plot=ax.scatter3D(df['arrival_date_year'],df['adr'],df["arrival_date_day_of_month"],cmap = my_cmap,alpha = 0.8,c =(df.Month))
plt.title("Adr Vs Visit Timing")
ax.set_xlabel('Year', fontweight ='bold')
ax.set_ylabel('Average Daily Rent (adr)', fontweight ='bold')
ax.set_zlabel('Date', fontweight ='bold')
fig.colorbar(plot, ax = ax, aspect = 5)
plt.show()

"""average Daily rent depend majorly on Date, but certainly Months plays a Major role as we can see that rent is less for the month of Dec and Jan Possibly due to off season, while july and august have the highest adr, also rent of all the hotels are increasing rapidly this can be concluded by seeing the width of the adr plane"""

df1=df[(df.stays_in_weekend_nights+df.stays_in_week_nights) <6]                 #again removing the anomaly to get a clear trend

fig = plt.figure(figsize = (20, 10))
ax = plt.axes(projection ="3d")
# Creating color map
my_cmap = plt.get_cmap('RdBu')
plot=ax.scatter3D(df1['arrival_date_year'],df1['adr'],df1["Month"],cmap = my_cmap,c =(df1.stays_in_weekend_nights+df1.stays_in_week_nights)) #adding weekend and weekdays to get total length of stay
plt.title("Adr, Visit Timing vs days of stay")
ax.set_xlabel('Year', fontweight ='bold')
ax.set_ylabel('Average Daily Rent (adr)', fontweight ='bold')
ax.set_zlabel('Month', fontweight ='bold')
fig.colorbar(plot, ax = ax, aspect = 5)
plt.show()

"""mid values hotel have longer staying customers, also people stay longer in the months of july and August, so to get the best daily rate one should book the hotel for atleast 5 days """

sns.catplot(data=df,y='adr',x='market_segment',height=15, aspect=0.5,kind="boxen",col='customer_type')              # Lets see which Market segment individual live in high tarrif rooms
plt.show()

"""* For Transient, Transient-Party and Group customers Online TA/To and direct market Segments Stay at hotels with high Adr followed by Aviation, offine TA/To and then Corporate
* where else in contract type Online and offline Ta Dominated 
"""

sns.catplot(data=df,y='adr',x='reservation_status',height=15, aspect=0.55,col='customer_type')

"""Transient Customers cancels thier booking most of the times, also they are the ones who does not show even after making bookings, where else groups are the most consistent in regards to their plans, also Transient customers books the most expensive rooms out of all segments"""

sns.catplot(data=df,y='adr',x='reservation_status',height=15, aspect=0.55,col='deposit_type',kind='box')           #Lets see Deposite type and customer's consistency

"""This plot actually tells a lot about customer behaviour, the customers who make non refundable booking are the least,so is their no show ratio, wherelse most people make no deposits while bookings and thus are most inconsistent as well"""

with sns.axes_style('white'):
    sns.jointplot('arrival_date_day_of_month', "adr", df[df.adr<200], kind='hex',height=10)         #price along the month is almost the same.

"""Lets take a look at Averages :"""

avg_daily_rate_vs_month=(df.groupby(by='arrival_date_month')['adr'].sum()/df.groupby(by='arrival_date_month')['adr'].count()).sort_values(ascending=False)
avg_daily_rate_vs_date=df.groupby(by='arrival_date_day_of_month')['adr'].sum()/(df.groupby(by='arrival_date_day_of_month')['adr'].count())
avg_daily_rate_vs_year=df.groupby(by='arrival_date_year')['adr'].sum()/(df.groupby(by='arrival_date_year')['adr'].count())
total_of_special_requests_vs_month=df.groupby(by='arrival_date_month')['total_of_special_requests'].sum().sort_values(ascending=False)
avg_special_requests_vs_month=(df.groupby(by='arrival_date_month')['total_of_special_requests'].sum()/df.groupby(by='arrival_date_month')['total_of_special_requests'].count()).sort_values(ascending=False)
avg_daily_rate_vs_hotel=df.groupby(by='hotel')['adr'].sum()/df.groupby(by='hotel')['adr'].count()
plots=[avg_daily_rate_vs_month,avg_daily_rate_vs_hotel,total_of_special_requests_vs_month,avg_special_requests_vs_month,avg_daily_rate_vs_date,avg_daily_rate_vs_year]
plot2=['avg_daily_rate_vs_month','avg_daily_rate_vs_hotel','total_of_special_requests_vs_month','avg_special_requests_vs_month','avg_daily_rate_vs_date','avg_daily_rate_vs_year']


count=0
for i in plots:
  plt.figure(figsize=(30,10))
  sns.barplot(i.index.astype(str),i.values)
  plt.xlabel(plot2[count].split('_vs_')[1])
  plt.ylabel(plot2[count].split('_vs_')[0])
  plt.xticks(rotation=90)
  plt.show()
  count+=1

"""Let's customize the Data for our Indian Public who want to get hotel room booked in this area, and tell them which agent they should contact.


*   Our priority is to get hotel which assign the room which we have reserved while booking
*   Hotel should have hosted some Indian guest previously as well
*   Avg_daily_price should be less than 100 Pound
* No intial Deposit is to be made



"""

df_indian_preference=df[(df['reserved_room_type']==df.assigned_room_type) & (df['country']=='IND') & (df['adr']<=100)  ]

def count_table(df):  
  column_list=['arrival_date_month','agent','hotel','country', 'is_canceled', 'lead_time', 'arrival_date_year',
          'arrival_date_week_number',
        'arrival_date_day_of_month', 'stays_in_weekend_nights',
        'stays_in_week_nights', 'adults', 'children', 'babies', 'meal',
          'market_segment', 'distribution_channel',
        'is_repeated_guest', 'previous_cancellations',
        'previous_bookings_not_canceled', 'reserved_room_type',
        'assigned_room_type', 'booking_changes', 'deposit_type', 
        'days_in_waiting_list', 'customer_type', 'adr',
        'required_car_parking_spaces', 'total_of_special_requests',
        'reservation_status', 'reservation_status_date']
  count_dataset=pd.DataFrame()
  distinct_features=[]                                                                                          #Empty list to know the number of distict features,sum of all these values, and sum of values top 10 comprises
  for i in column_list:                                                                                               
    count_dataset[i]= pd.Series(df[i].value_counts().sort_values(ascending=False).head(10).index)      
    count_dataset[f'{i}_count']=pd.Series(df[i].value_counts().sort_values(ascending=False).head(10).values).astype('int')   
    distinct_features.append((len(df[i].value_counts().index),df[i].value_counts().sum(),df[i].value_counts().sort_values(ascending=False).head(10).sum())) 
  final_tally=list(zip(column_list,distinct_features))                                                           #Zipping with column_list
  count_dataset   
  col_ref={}  
  for i in column_list:
    if i in ['children','country','agent','company']:                                                           #colur red shows the features having some Nan
      col_ref[i]='background-color: red'  
    else:
      col_ref[i]='background-color: blue'                                                                       #colur blue shows the features 
    temp=f'{i}_count'
    col_ref[temp]='background-color: green'                                                                     #colur blue shows the count
  def Nan_as_black(val):
    if str(val)=='nan':
      color = 'black'
      return 'color: %s' % color
  count_dataset=count_dataset.style.apply(lambda x: pd.DataFrame(col_ref, index=count_dataset.index, columns=count_dataset.columns).fillna(''), axis=None).highlight_null('black').applymap(Nan_as_black)
  return count_dataset

count_table(df_indian_preference)

"""From the Data it can be said that agent 9 should be the go to choice for indian who want a room in the hotel.


Calculating Footfall for next month using basic maths:
"""

df_sept=df[df['arrival_date_month']=='September']

foot_fall_df=pd.DataFrame(df[df['arrival_date_year']!= 2015].groupby('arrival_date_month')['arrival_date_year'].value_counts())

months=['January','February','March','April','May','June','July','August']
growth_rate_list=[]
for i in months:
  val=(foot_fall_df.loc[i].loc[2017]-foot_fall_df.loc[i].loc[2016])/100
  growth_rate_list.append(val)
avg_growth_rate=np.sum(growth_rate_list)/len(months)
print(f'{avg_growth_rate}%')
month=['September','October','November','December']
for i in month:
  foot_fall_sept=(foot_fall_df.loc[i].loc[2016])*(100+avg_growth_rate)/100
  print(Fore.RED+f'Expected FootFall for {i} Month = {int(foot_fall_sept)}')

"""These Footfall are Calculated using Basic Maths and is not accurate, but we can Build an ML Model which could predict this value to a great accuracy considering various features and trends."""